{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSTR Weekly Chest Cases Crawler\n",
    "##### Dependency\n",
    "- bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://kstr.radiology.or.kr\"\n",
    "archive_url = \"/weekly/archive/\"\n",
    "case_list_url = \"list.php?menu_num=2&sub_num=\"\n",
    "yearly_urls = [base_url+archive_url+case_list_url+str(i) for i in range(1997, 2024)]\n",
    "datas = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 9984.06it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 6733.51it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10525.23it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 9913.27it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 7305.88it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "Crawling case 779: 100%|██████████| 10/10 [00:00<00:00, 21.06it/s]\n",
      "Crawling case 789: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Crawling case 792: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n",
      "Crawling case 802: 100%|██████████| 10/10 [00:05<00:00,  1.98it/s]\n",
      "Crawling case 812: 100%|██████████| 10/10 [00:04<00:00,  2.11it/s]\n",
      "Crawling case 822: 100%|██████████| 10/10 [00:04<00:00,  2.11it/s]\n",
      "Crawling case 832: 100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n",
      "Crawling case 842: 100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n",
      "Crawling case 844: 100%|██████████| 2/2 [00:00<00:00,  2.13it/s]\n",
      "Crawling case 854: 100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n",
      "Crawling case 864: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Crawling case 874: 100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n",
      "Crawling case 884: 100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n",
      "Crawling case 894: 100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n",
      "Crawling case 896: 100%|██████████| 2/2 [00:00<00:00,  2.18it/s]\n",
      "Crawling case 906: 100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n",
      "Crawling case 916: 100%|██████████| 10/10 [00:04<00:00,  2.02it/s]\n",
      "Crawling case 926: 100%|██████████| 10/10 [00:05<00:00,  1.93it/s]\n",
      "Crawling case 936: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Crawling case 946: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Crawling case 948: 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n",
      "Crawling case 958: 100%|██████████| 10/10 [00:04<00:00,  2.11it/s]\n",
      "Crawling case 968: 100%|██████████| 10/10 [00:04<00:00,  2.11it/s]\n",
      "Crawling case 978: 100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n",
      "Crawling case 988: 100%|██████████| 10/10 [00:04<00:00,  2.00it/s]\n",
      "Crawling case 998: 100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n",
      "Crawling case 1000: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "Crawling case 1010: 100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n",
      "Crawling case 1020: 100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n",
      "Crawling case 1030: 100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n",
      "Crawling case 1040: 100%|██████████| 10/10 [00:04<00:00,  2.06it/s]\n",
      "Crawling case 1050: 100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n",
      "Crawling case 1052: 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n",
      "Crawling case 1062: 100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n",
      "Crawling case 1072: 100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n",
      "Crawling case 1082: 100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "Crawling case 1092: 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]\n",
      "Crawling case 1102: 100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n",
      "Crawling case 1105: 100%|██████████| 3/3 [00:01<00:00,  2.13it/s]\n",
      "Crawling case 1115: 100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n",
      "Crawling case 1125: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Crawling case 1135: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Crawling case 1145: 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]\n",
      "Crawling case 1155: 100%|██████████| 10/10 [00:04<00:00,  2.14it/s]\n",
      "Crawling case 1157: 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n",
      "Crawling case 1167: 100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n",
      "Crawling case 1178: 100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "Crawling case 1188: 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]\n",
      "Crawling case 1198: 100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n",
      "Crawling case 1208: 100%|██████████| 10/10 [00:04<00:00,  2.14it/s]\n",
      "Crawling case 1210: 100%|██████████| 2/2 [00:00<00:00,  2.23it/s]\n",
      "Crawling case 1220: 100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "Crawling case 1230: 100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n",
      "Crawling case 1240: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n",
      "Crawling case 1250: 100%|██████████| 10/10 [00:04<00:00,  2.01it/s]\n",
      "Crawling case 1260: 100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n",
      "Crawling case 1262: 100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n",
      "Crawling case 1272: 100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "Crawling case 1282: 100%|██████████| 10/10 [00:04<00:00,  2.05it/s]\n",
      "Crawling case 1292: 100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "Crawling case 1302: 100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n",
      "Crawling case 1312: 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]\n",
      "Crawling case 1314: 100%|██████████| 2/2 [00:00<00:00,  2.04it/s]\n",
      "Crawling case 1324: 100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n",
      "Crawling case 1334: 100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n",
      "Crawling case 1343: 100%|██████████| 9/9 [00:05<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for year in yearly_urls:\n",
    "    response = urlopen(year)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    pages = soup.find(\"li\", {\"class\" : \"next\"})\n",
    "    page_li = pages.find_previous_sibling(\"li\")\n",
    "    page_num = int(page_li.text.replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "\n",
    "    for page in range(1, page_num+1):\n",
    "        response = urlopen(f\"{year}&page={page}\")\n",
    "        soup = BeautifulSoup(response, 'html.parser')\n",
    "        cases = soup.find_all(\"span\", {\"class\" : \"tit\"})\n",
    "\n",
    "        pbar = tqdm(cases)\n",
    "        for case in pbar:\n",
    "            # case number, case link\n",
    "            case_id = int(case.text.split()[-1].replace(\"]\",\"\"))\n",
    "            \n",
    "\n",
    "            #\n",
    "            if (case_id <= len(datas)): continue\n",
    "            #\n",
    "\n",
    "            \n",
    "            pbar.set_description(f\"Crawling case {case_id}\")\n",
    "            href = case.parent[\"href\"].split(\"&\")[0]\n",
    "            link = (base_url + archive_url + href)\n",
    "            \n",
    "            case_response = urlopen(link)\n",
    "            case_soup = BeautifulSoup(case_response, 'html.parser')\n",
    "\n",
    "            # case date\n",
    "            div_case = case_soup.find(\"div\", {\"class\" : \"case\"})\n",
    "            case_date = div_case.find(\"span\", {\"class\" : \"date\"}).text.split()[-1]\n",
    "\n",
    "            # case age / sex / complaint\n",
    "            div_case_lis = div_case.find_all(\"li\")\n",
    "            for li in div_case_lis:\n",
    "                if \"Age\" in li.text:\n",
    "                    age_sex = li.text.split(\"Sex\")[1].strip().replace(\" \", \"\") + \" \"\n",
    "                    age, sex = age_sex.split(\"/\")\n",
    "                    sex = sex.strip()\n",
    "                if \"Complaint\" in li.text:\n",
    "                    complaint = li.text.replace(\"Chief Complaint\", \"\")\n",
    "\n",
    "            # case diagnosis / findings / brief review\n",
    "            div_diag_dl = case_soup.find(\"dl\", {\"class\" : \"toggleCon\"})\n",
    "            diagnosis = div_diag_dl.find(string=\"Diagnosis\").parent.find_next_sibling(\"dd\").text\n",
    "            findings = div_diag_dl.find(string=\"Radiologic Findings\").parent.find_next_sibling(\"dd\").text\n",
    "            brief_review = div_diag_dl.find(string=\"Brief Review\").parent.find_next_sibling(\"dd\").text\n",
    "\n",
    "            # case images\n",
    "            img_num = len(case_soup.find(\"ul\", {\"class\" : \"thumbList\"}).find_all(\"li\"))\n",
    "            p_img = case_soup.find(\"div\", {\"class\" : \"bigPhoto\"}).find(\"p\", {\"class\" : \"img\"})\n",
    "            img_src = p_img.find(string=lambda text: isinstance(text, Comment)).split('\"')[1]\n",
    "            img_links = [base_url + img_src.replace(\"-1.\", f\"-{i}.\") for i in range(1, img_num+1)]\n",
    "            \n",
    "            # correct answer rate\n",
    "            div_answer = case_soup.find(\"div\", {\"class\" : \"answer\"})\n",
    "            applicants = int(div_answer.find(\"h3\").find(\"span\", {\"class\" : \"fcRed\"}).text)\n",
    "            toggles = div_answer.find_all(\"a\", {\"class\" : \"_toggle\"})\n",
    "\n",
    "            ans_rates = []\n",
    "            for t in toggles:\n",
    "                if \"Correct Answer\" in t.text:\n",
    "                    fraction, percentage = t.text.split(\":\")[1].strip().replace(\" \", \"\").split(\",\")\n",
    "                    if \"Semi\" in t.text: ans_rate = f\"semi:{fraction}\"\n",
    "                    elif \"Diff\" in t.text: ans_rate = f\"diff:{fraction}\"\n",
    "                    else: ans_rate = f\"correct:{fraction}\"\n",
    "                    ans_rates.append(ans_rate)\n",
    "\n",
    "            data = {\n",
    "                \"id\" : case_id,\n",
    "                \"link\" : link,\n",
    "                \"date\" : case_date,\n",
    "                \"age\" : age,\n",
    "                \"sex\" : sex,\n",
    "                \"complaint\" : complaint,\n",
    "                \"diagnosis\" : diagnosis,\n",
    "                \"findings\" : findings,\n",
    "                \"brief_review\" : brief_review,\n",
    "                \"img_links\" : img_links,\n",
    "                \"applicants\" : applicants,\n",
    "                \"answer_rates\" : ans_rates\n",
    "            }\n",
    "\n",
    "            datas.append(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = datas[0].keys()\n",
    "with open(\"../crawled_data/kstr_data.csv\", \"w\", encoding=\"utf-8-sig\", newline=\"\") as csv_file: # Add newline=\"\"\n",
    "    csv_writer = csv.DictWriter(csv_file, keys) # Pass the writer to DictWriter\n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
